{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> <center> Resume Experiment Analysis¶ <center> <h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center> Preet Khowaja <center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downloading the data and importing relevant packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import statsmodels.formula.api as smf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>education</th>\n",
       "      <th>ofjobs</th>\n",
       "      <th>yearsexp</th>\n",
       "      <th>computerskills</th>\n",
       "      <th>call</th>\n",
       "      <th>female</th>\n",
       "      <th>black</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   education  ofjobs  yearsexp  computerskills  call  female  black\n",
       "0          4       2         6               1   0.0     1.0    0.0\n",
       "1          3       3         6               1   0.0     1.0    0.0\n",
       "2          4       1         6               1   0.0     1.0    1.0\n",
       "3          3       4         6               1   0.0     1.0    1.0\n",
       "4          3       3        22               1   0.0     1.0    0.0\n",
       "5          4       2         6               0   0.0     0.0    0.0\n",
       "6          4       2         5               1   0.0     1.0    0.0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resume_data = pd.read_stata(\"resume_experiment.dta\")\n",
    "resume_data.head(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4870, 7)\n",
      "education            int8\n",
      "ofjobs               int8\n",
      "yearsexp             int8\n",
      "computerskills       int8\n",
      "call              float32\n",
      "female            float32\n",
      "black             float32\n",
      "dtype: object\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "education         0\n",
       "ofjobs            0\n",
       "yearsexp          0\n",
       "computerskills    0\n",
       "call              0\n",
       "female            0\n",
       "black             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking dimensions/type of data\n",
    "print(resume_data.shape)\n",
    "print(resume_data.dtypes)\n",
    "\n",
    "# Check for missing data\n",
    "resume_data.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1¶\n",
    "\n",
    "**Check for balance in terms of applicant gender (female), computer skills (computerskills), and years of experience (yearsexp) across the two arms of the experiment (i.e. by black). Calculate both the differences across treatment arms and test for statistical significance of these differences. Do gender and computer skills look balanced across race groups?** \n",
    "\n",
    "The p-values we obtain while performing a t-test for gender is 0.377, indicating that both groups are balanced with regards to gender. However, they are not balanced when it comes to computer skills since the p-value is 0.030. This indicates that there is a statistically significant difference between the two groups' computer skills. They are also balanced when it comes to years of experience. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividing data by black variable\n",
    "black_data = resume_data[resume_data['black'] == 1]\n",
    "non_black_data = resume_data[resume_data['black'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The t-test result for gender is:\n",
      "Ttest_indResult(statistic=0.8841321018026016, pvalue=0.37666856909823254)\n",
      "The t-test result for computer skills is:\n",
      "Ttest_indResult(statistic=2.1664271042751966, pvalue=0.030326933955391936)\n",
      "The t-test result for years of experience is:\n",
      "Ttest_indResult(statistic=-0.18461970685747395, pvalue=0.8535350182481283)\n"
     ]
    }
   ],
   "source": [
    "# Checking for balance across gender, computer skills\n",
    "# and yearsexp using a t-test\n",
    "print(\"The t-test result for gender is:\")\n",
    "print(stats.ttest_ind(black_data['female'], non_black_data['female']))\n",
    "print(\"The t-test result for computer skills is:\")\n",
    "print(stats.ttest_ind(black_data['computerskills'], non_black_data['computerskills']))\n",
    "print(\"The t-test result for years of experience is:\")\n",
    "print(stats.ttest_ind(black_data['yearsexp'], non_black_data['yearsexp']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2¶\n",
    "\n",
    "**Do a similar tabulation for education (education).** \n",
    "\n",
    "**Because these are categorical, you shouldn’t just calculate and compare means – you should compare share of observations with each value separately using a ttest, or do a chi-squared test (technically chi-squared is the correct test, but I’m ok with either).**\n",
    "\n",
    "**Does education and the number of previous jobs look balanced across racial groups?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The p-value of the test is 0.492\n"
     ]
    }
   ],
   "source": [
    "# Computing frequencies by education\n",
    "frequencies = pd.crosstab(resume_data.black,resume_data.education)\n",
    "\n",
    "# Testing whether these frequencies are statistically similar\n",
    "# in both racial categories\n",
    "chi2, p, dof, ex = stats.chi2_contingency(frequencies)\n",
    "\n",
    "print(\"The p-value of the test is {:.3f}\".format(p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The p-value of the test is 0.741\n"
     ]
    }
   ],
   "source": [
    "# Computing frequencies by education\n",
    "frequencies2 = pd.crosstab(resume_data.black,resume_data.ofjobs)\n",
    "\n",
    "# Testing whether these frequencies are statistically similar\n",
    "# in both racial categories\n",
    "chi22, p2, dof2, ex2 = stats.chi2_contingency(frequencies2)\n",
    "\n",
    "print(\"The p-value of the test is {:.3f}\".format(p2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to these p-values (> 0.05), we can conclude that there isn't enough evidence to reject the null hypothesis, $H_0$ which claims that the two groups are balanced on education and number of previous jobs. Hence, we can say that there is balance on these two variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3¶\n",
    "\n",
    "**What do you make of the overall results on resume characteristics? Why do we care about whether these variables look similar across the race groups?**\n",
    "\n",
    "Overall, the groups look balanced in gender, education, number of previous jobs and years of experience. There seems to be an imbalance in the computer skills variable. However, the imbalance is not significant at the 0.01 level, just the 0.05 level. \n",
    "The reason it is important to control for these variables in a causal study such as this one is to ensure that the treatment effect is attributed to the treatment and not one of these factors. For example, we want to ensure that it is truly having a black-sounding name that affects likelihood of getting an interview call rather than someone being female. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4¶\n",
    "\n",
    "**The variable of interest in the data set is the variable call, which indicates a call back for an interview. Perform a two-sample t-test comparing applicants with black sounding names and white sounding names.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_indResult(statistic=-4.114705290861751, pvalue=3.940802103128886e-05)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.ttest_ind(black_data.call, non_black_data.call)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the t-test above, we observe no statistical difference between the calls received by black sounding names and non-black sounding names. The p-value is very large and we cannot reject the null hypothesis. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 5¶\n",
    "\n",
    "**Now, use a regression model to estimate the differential likelihood of being called back by applicant race (i.e. the racial discrimination by employers). Is the difference statistically significant?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>          <td>call</td>       <th>  R-squared:         </th> <td>   0.003</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.003</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   16.92</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Thu, 27 Jan 2022</td> <th>  Prob (F-statistic):</th> <td>3.96e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>13:29:18</td>     <th>  Log-Likelihood:    </th> <td> -562.24</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  4870</td>      <th>  AIC:               </th> <td>   1128.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  4868</td>      <th>  BIC:               </th> <td>   1141.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>         <td>HC3</td>       <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td>    0.0965</td> <td>    0.006</td> <td>   16.121</td> <td> 0.000</td> <td>    0.085</td> <td>    0.108</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>black</th>     <td>   -0.0320</td> <td>    0.008</td> <td>   -4.114</td> <td> 0.000</td> <td>   -0.047</td> <td>   -0.017</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>2969.205</td> <th>  Durbin-Watson:     </th> <td>   1.440</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th>  <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>18927.068</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>           <td> 3.068</td>  <th>  Prob(JB):          </th> <td>    0.00</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>       <td>10.458</td>  <th>  Cond. No.          </th> <td>    2.62</td> \n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors are heteroscedasticity robust (HC3)"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                   call   R-squared:                       0.003\n",
       "Model:                            OLS   Adj. R-squared:                  0.003\n",
       "Method:                 Least Squares   F-statistic:                     16.92\n",
       "Date:                Thu, 27 Jan 2022   Prob (F-statistic):           3.96e-05\n",
       "Time:                        13:29:18   Log-Likelihood:                -562.24\n",
       "No. Observations:                4870   AIC:                             1128.\n",
       "Df Residuals:                    4868   BIC:                             1141.\n",
       "Df Model:                           1                                         \n",
       "Covariance Type:                  HC3                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept      0.0965      0.006     16.121      0.000       0.085       0.108\n",
       "black         -0.0320      0.008     -4.114      0.000      -0.047      -0.017\n",
       "==============================================================================\n",
       "Omnibus:                     2969.205   Durbin-Watson:                   1.440\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            18927.068\n",
       "Skew:                           3.068   Prob(JB):                         0.00\n",
       "Kurtosis:                      10.458   Cond. No.                         2.62\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors are heteroscedasticity robust (HC3)\n",
       "\"\"\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting a regression model\n",
    "model_1 = smf.ols(\"call ~ black\", resume_data).fit()\n",
    "model_1.get_robustcov_results(cov_type=\"HC3\").summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the linear model above, the difference of being called for an interview based on perceived race is very significant and black-sounding names have a 3.2% lower chance of being called for an interview."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 6¶\n",
    "\n",
    "**Now let’s see if we can improve our estimates by adding in other variables as controls. Add in education, yearsexp, female, and computerskills – be sure to treat education as a categorical variable!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>          <td>call</td>       <th>  R-squared:         </th> <td>   0.008</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.006</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   4.350</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Thu, 27 Jan 2022</td> <th>  Prob (F-statistic):</th> <td>3.04e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>13:29:19</td>     <th>  Log-Likelihood:    </th> <td> -551.02</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  4870</td>      <th>  AIC:               </th> <td>   1120.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  4861</td>      <th>  BIC:               </th> <td>   1178.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     8</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>         <td>HC3</td>       <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "          <td></td>             <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>         <td>    0.0821</td> <td>    0.040</td> <td>    2.053</td> <td> 0.040</td> <td>    0.004</td> <td>    0.160</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(education)[T.1]</th> <td>   -0.0017</td> <td>    0.057</td> <td>   -0.030</td> <td> 0.976</td> <td>   -0.113</td> <td>    0.110</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(education)[T.2]</th> <td>-8.953e-05</td> <td>    0.042</td> <td>   -0.002</td> <td> 0.998</td> <td>   -0.082</td> <td>    0.082</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(education)[T.3]</th> <td>   -0.0025</td> <td>    0.039</td> <td>   -0.065</td> <td> 0.948</td> <td>   -0.079</td> <td>    0.074</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(education)[T.4]</th> <td>   -0.0047</td> <td>    0.038</td> <td>   -0.124</td> <td> 0.901</td> <td>   -0.080</td> <td>    0.070</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>black</th>             <td>   -0.0316</td> <td>    0.008</td> <td>   -4.076</td> <td> 0.000</td> <td>   -0.047</td> <td>   -0.016</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>yearsexp</th>          <td>    0.0032</td> <td>    0.001</td> <td>    3.665</td> <td> 0.000</td> <td>    0.001</td> <td>    0.005</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>female</th>            <td>    0.0112</td> <td>    0.010</td> <td>    1.165</td> <td> 0.244</td> <td>   -0.008</td> <td>    0.030</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>computerskills</th>    <td>   -0.0186</td> <td>    0.011</td> <td>   -1.616</td> <td> 0.106</td> <td>   -0.041</td> <td>    0.004</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>2950.646</td> <th>  Durbin-Watson:     </th> <td>   1.448</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th>  <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>18631.250</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>           <td> 3.047</td>  <th>  Prob(JB):          </th> <td>    0.00</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>       <td>10.395</td>  <th>  Cond. No.          </th> <td>    225.</td> \n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors are heteroscedasticity robust (HC3)"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                   call   R-squared:                       0.008\n",
       "Model:                            OLS   Adj. R-squared:                  0.006\n",
       "Method:                 Least Squares   F-statistic:                     4.350\n",
       "Date:                Thu, 27 Jan 2022   Prob (F-statistic):           3.04e-05\n",
       "Time:                        13:29:19   Log-Likelihood:                -551.02\n",
       "No. Observations:                4870   AIC:                             1120.\n",
       "Df Residuals:                    4861   BIC:                             1178.\n",
       "Df Model:                           8                                         \n",
       "Covariance Type:                  HC3                                         \n",
       "=====================================================================================\n",
       "                        coef    std err          t      P>|t|      [0.025      0.975]\n",
       "-------------------------------------------------------------------------------------\n",
       "Intercept             0.0821      0.040      2.053      0.040       0.004       0.160\n",
       "C(education)[T.1]    -0.0017      0.057     -0.030      0.976      -0.113       0.110\n",
       "C(education)[T.2] -8.953e-05      0.042     -0.002      0.998      -0.082       0.082\n",
       "C(education)[T.3]    -0.0025      0.039     -0.065      0.948      -0.079       0.074\n",
       "C(education)[T.4]    -0.0047      0.038     -0.124      0.901      -0.080       0.070\n",
       "black                -0.0316      0.008     -4.076      0.000      -0.047      -0.016\n",
       "yearsexp              0.0032      0.001      3.665      0.000       0.001       0.005\n",
       "female                0.0112      0.010      1.165      0.244      -0.008       0.030\n",
       "computerskills       -0.0186      0.011     -1.616      0.106      -0.041       0.004\n",
       "==============================================================================\n",
       "Omnibus:                     2950.646   Durbin-Watson:                   1.448\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            18631.250\n",
       "Skew:                           3.047   Prob(JB):                         0.00\n",
       "Kurtosis:                      10.395   Cond. No.                         225.\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors are heteroscedasticity robust (HC3)\n",
       "\"\"\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Fitting a model with other predictors\n",
    "model_2 = smf.ols(\"call ~ black + yearsexp + \"\n",
    "\"female + computerskills + C(education)\", resume_data).fit()\n",
    "model_2.get_robustcov_results(cov_type=\"HC3\").summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 7¶\n",
    "\n",
    "**These effects are the average effects. Now let’s look for heterogeneous treatment effects.**\n",
    "\n",
    "**Look only at candidates with high educations. Is there more or less racial discrimination among these highly educated candidates? Is the difference statistically significant?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>          <td>call</td>       <th>  R-squared:         </th> <td>   0.008</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.006</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   42.83</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Thu, 27 Jan 2022</td> <th>  Prob (F-statistic):</th> <td>4.63e-82</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>13:29:19</td>     <th>  Log-Likelihood:    </th> <td> -550.76</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  4870</td>      <th>  AIC:               </th> <td>   1122.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  4860</td>      <th>  BIC:               </th> <td>   1186.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     9</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>         <td>HC3</td>       <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "                 <td></td>                   <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>                      <td>    0.0544</td> <td>    0.015</td> <td>    3.517</td> <td> 0.000</td> <td>    0.024</td> <td>    0.085</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>high_ed[T.no_col_degree]</th>       <td>    0.0331</td> <td>    0.026</td> <td>    1.281</td> <td> 0.200</td> <td>   -0.018</td> <td>    0.084</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(education)[T.1]</th>              <td>   -0.0023</td> <td>    0.057</td> <td>   -0.040</td> <td> 0.968</td> <td>   -0.114</td> <td>    0.110</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(education)[T.2]</th>              <td>   -0.0012</td> <td>    0.042</td> <td>   -0.030</td> <td> 0.976</td> <td>   -0.083</td> <td>    0.081</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(education)[T.3]</th>              <td>   -0.0036</td> <td>    0.039</td> <td>   -0.092</td> <td> 0.927</td> <td>   -0.080</td> <td>    0.073</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(education)[T.4]</th>              <td>    0.0212</td> <td>    0.014</td> <td>    1.501</td> <td> 0.133</td> <td>   -0.007</td> <td>    0.049</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>black</th>                          <td>   -0.0282</td> <td>    0.009</td> <td>   -3.091</td> <td> 0.002</td> <td>   -0.046</td> <td>   -0.010</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>black:high_ed[T.no_col_degree]</th> <td>   -0.0123</td> <td>    0.017</td> <td>   -0.710</td> <td> 0.478</td> <td>   -0.046</td> <td>    0.022</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>yearsexp</th>                       <td>    0.0032</td> <td>    0.001</td> <td>    3.672</td> <td> 0.000</td> <td>    0.001</td> <td>    0.005</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>female</th>                         <td>    0.0112</td> <td>    0.010</td> <td>    1.157</td> <td> 0.247</td> <td>   -0.008</td> <td>    0.030</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>computerskills</th>                 <td>   -0.0186</td> <td>    0.011</td> <td>   -1.618</td> <td> 0.106</td> <td>   -0.041</td> <td>    0.004</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>2950.182</td> <th>  Durbin-Watson:     </th> <td>   1.448</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th>  <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>18623.859</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>           <td> 3.046</td>  <th>  Prob(JB):          </th> <td>    0.00</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>       <td>10.393</td>  <th>  Cond. No.          </th> <td>5.82e+15</td> \n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors are heteroscedasticity robust (HC3)<br/>[2] The smallest eigenvalue is 1.28e-26. This might indicate that there are<br/>strong multicollinearity problems or that the design matrix is singular."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                   call   R-squared:                       0.008\n",
       "Model:                            OLS   Adj. R-squared:                  0.006\n",
       "Method:                 Least Squares   F-statistic:                     42.83\n",
       "Date:                Thu, 27 Jan 2022   Prob (F-statistic):           4.63e-82\n",
       "Time:                        13:29:19   Log-Likelihood:                -550.76\n",
       "No. Observations:                4870   AIC:                             1122.\n",
       "Df Residuals:                    4860   BIC:                             1186.\n",
       "Df Model:                           9                                         \n",
       "Covariance Type:                  HC3                                         \n",
       "==================================================================================================\n",
       "                                     coef    std err          t      P>|t|      [0.025      0.975]\n",
       "--------------------------------------------------------------------------------------------------\n",
       "Intercept                          0.0544      0.015      3.517      0.000       0.024       0.085\n",
       "high_ed[T.no_col_degree]           0.0331      0.026      1.281      0.200      -0.018       0.084\n",
       "C(education)[T.1]                 -0.0023      0.057     -0.040      0.968      -0.114       0.110\n",
       "C(education)[T.2]                 -0.0012      0.042     -0.030      0.976      -0.083       0.081\n",
       "C(education)[T.3]                 -0.0036      0.039     -0.092      0.927      -0.080       0.073\n",
       "C(education)[T.4]                  0.0212      0.014      1.501      0.133      -0.007       0.049\n",
       "black                             -0.0282      0.009     -3.091      0.002      -0.046      -0.010\n",
       "black:high_ed[T.no_col_degree]    -0.0123      0.017     -0.710      0.478      -0.046       0.022\n",
       "yearsexp                           0.0032      0.001      3.672      0.000       0.001       0.005\n",
       "female                             0.0112      0.010      1.157      0.247      -0.008       0.030\n",
       "computerskills                    -0.0186      0.011     -1.618      0.106      -0.041       0.004\n",
       "==============================================================================\n",
       "Omnibus:                     2950.182   Durbin-Watson:                   1.448\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            18623.859\n",
       "Skew:                           3.046   Prob(JB):                         0.00\n",
       "Kurtosis:                      10.393   Cond. No.                     5.82e+15\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors are heteroscedasticity robust (HC3)\n",
       "[2] The smallest eigenvalue is 1.28e-26. This might indicate that there are\n",
       "strong multicollinearity problems or that the design matrix is singular.\n",
       "\"\"\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first we create a new variable for higher ed\n",
    "resume_data['high_ed'] = np.where(resume_data.education == 4,\n",
    " 'col_degree', 'no_col_degree')\n",
    "\n",
    "# Then we create a regression and add the interaction \n",
    "# between race and higher ed\n",
    "model_3 = smf.ols(\"call ~ black + \"\n",
    "\"black:high_ed + high_ed + yearsexp + \"\n",
    "\"female + computerskills + C(education) \", resume_data).fit()\n",
    "model_3.get_robustcov_results(cov_type=\"HC3\").summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The intercept of black and not being a college graduate is -0.0123, which indicates that the probability of getting a call falls. The difference among college graduates is not statistically significant(according to the p-value). This means being a black non-college graduate is not really different from being a black college graduate in terms of the likelihood of getting an interview call. However, as discussed in class, p-values can sometimes be misleading. It may very well be that this experiment is underpowered and we need more samples to make a conclusive decision. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 8¶\n",
    "\n",
    "**Now let’s compare men and women – is discrimination greater for Black men or Black women? Is the difference statistically significant?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>          <td>call</td>       <th>  R-squared:         </th> <td>   0.008</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.006</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   38.93</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Thu, 27 Jan 2022</td> <th>  Prob (F-statistic):</th> <td>3.23e-81</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>13:29:19</td>     <th>  Log-Likelihood:    </th> <td> -550.76</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  4870</td>      <th>  AIC:               </th> <td>   1124.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  4859</td>      <th>  BIC:               </th> <td>   1195.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    10</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>         <td>HC3</td>       <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "                 <td></td>                   <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>                      <td>    0.0540</td> <td>    0.016</td> <td>    3.327</td> <td> 0.001</td> <td>    0.022</td> <td>    0.086</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>high_ed[T.no_col_degree]</th>       <td>    0.0329</td> <td>    0.026</td> <td>    1.264</td> <td> 0.206</td> <td>   -0.018</td> <td>    0.084</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(education)[T.1]</th>              <td>   -0.0024</td> <td>    0.057</td> <td>   -0.042</td> <td> 0.967</td> <td>   -0.115</td> <td>    0.110</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(education)[T.2]</th>              <td>   -0.0012</td> <td>    0.042</td> <td>   -0.030</td> <td> 0.976</td> <td>   -0.083</td> <td>    0.081</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(education)[T.3]</th>              <td>   -0.0036</td> <td>    0.039</td> <td>   -0.092</td> <td> 0.927</td> <td>   -0.080</td> <td>    0.073</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(education)[T.4]</th>              <td>    0.0211</td> <td>    0.014</td> <td>    1.478</td> <td> 0.140</td> <td>   -0.007</td> <td>    0.049</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>black</th>                          <td>   -0.0272</td> <td>    0.016</td> <td>   -1.748</td> <td> 0.080</td> <td>   -0.058</td> <td>    0.003</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>black:high_ed[T.no_col_degree]</th> <td>   -0.0121</td> <td>    0.018</td> <td>   -0.671</td> <td> 0.502</td> <td>   -0.047</td> <td>    0.023</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>black:female</th>                   <td>   -0.0013</td> <td>    0.019</td> <td>   -0.070</td> <td> 0.944</td> <td>   -0.038</td> <td>    0.035</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>yearsexp</th>                       <td>    0.0032</td> <td>    0.001</td> <td>    3.673</td> <td> 0.000</td> <td>    0.001</td> <td>    0.005</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>female</th>                         <td>    0.0118</td> <td>    0.015</td> <td>    0.810</td> <td> 0.418</td> <td>   -0.017</td> <td>    0.040</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>computerskills</th>                 <td>   -0.0186</td> <td>    0.011</td> <td>   -1.618</td> <td> 0.106</td> <td>   -0.041</td> <td>    0.004</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>2950.179</td> <th>  Durbin-Watson:     </th> <td>   1.448</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th>  <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>18623.866</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>           <td> 3.046</td>  <th>  Prob(JB):          </th> <td>    0.00</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>       <td>10.393</td>  <th>  Cond. No.          </th> <td>5.94e+15</td> \n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors are heteroscedasticity robust (HC3)<br/>[2] The smallest eigenvalue is 1.23e-26. This might indicate that there are<br/>strong multicollinearity problems or that the design matrix is singular."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                   call   R-squared:                       0.008\n",
       "Model:                            OLS   Adj. R-squared:                  0.006\n",
       "Method:                 Least Squares   F-statistic:                     38.93\n",
       "Date:                Thu, 27 Jan 2022   Prob (F-statistic):           3.23e-81\n",
       "Time:                        13:29:19   Log-Likelihood:                -550.76\n",
       "No. Observations:                4870   AIC:                             1124.\n",
       "Df Residuals:                    4859   BIC:                             1195.\n",
       "Df Model:                          10                                         \n",
       "Covariance Type:                  HC3                                         \n",
       "==================================================================================================\n",
       "                                     coef    std err          t      P>|t|      [0.025      0.975]\n",
       "--------------------------------------------------------------------------------------------------\n",
       "Intercept                          0.0540      0.016      3.327      0.001       0.022       0.086\n",
       "high_ed[T.no_col_degree]           0.0329      0.026      1.264      0.206      -0.018       0.084\n",
       "C(education)[T.1]                 -0.0024      0.057     -0.042      0.967      -0.115       0.110\n",
       "C(education)[T.2]                 -0.0012      0.042     -0.030      0.976      -0.083       0.081\n",
       "C(education)[T.3]                 -0.0036      0.039     -0.092      0.927      -0.080       0.073\n",
       "C(education)[T.4]                  0.0211      0.014      1.478      0.140      -0.007       0.049\n",
       "black                             -0.0272      0.016     -1.748      0.080      -0.058       0.003\n",
       "black:high_ed[T.no_col_degree]    -0.0121      0.018     -0.671      0.502      -0.047       0.023\n",
       "black:female                      -0.0013      0.019     -0.070      0.944      -0.038       0.035\n",
       "yearsexp                           0.0032      0.001      3.673      0.000       0.001       0.005\n",
       "female                             0.0118      0.015      0.810      0.418      -0.017       0.040\n",
       "computerskills                    -0.0186      0.011     -1.618      0.106      -0.041       0.004\n",
       "==============================================================================\n",
       "Omnibus:                     2950.179   Durbin-Watson:                   1.448\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            18623.866\n",
       "Skew:                           3.046   Prob(JB):                         0.00\n",
       "Kurtosis:                      10.393   Cond. No.                     5.94e+15\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors are heteroscedasticity robust (HC3)\n",
       "[2] The smallest eigenvalue is 1.23e-26. This might indicate that there are\n",
       "strong multicollinearity problems or that the design matrix is singular.\n",
       "\"\"\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Adding an interaction term for black\n",
    "#  and female\n",
    "model_4 = smf.ols(\"call ~ black + black:high_ed + \"\n",
    "\"black:female + high_ed + yearsexp + \"\n",
    "\"female + computerskills + C(education) \", resume_data).fit()\n",
    "model_4.get_robustcov_results(cov_type=\"HC3\").summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The intercept indicates that being a black woman reduces your likelihood of getting a call. However, the p-value for this is not significant, indicating that this difference between black men and women is not significant statistically."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 9¶\n",
    "\n",
    "**Calculate and/or lookup the following online:**\n",
    "\n",
    "**What is the share of applicants in our dataset with college degrees?**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The percentage of people with a college degree is 71.95%\n"
     ]
    }
   ],
   "source": [
    "resume_data[resume_data.high_ed == 'col_degree'].shape[0]\n",
    "resume_data.shape[0]\n",
    "perc = (3504/4870) * 100\n",
    "print(f\"The percentage of people with a college degree is {perc:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What share of Black adult Americans have college degrees (i.e. have completed a bachelors degree)?**\n",
    "\n",
    "The statistic is 16.% for adult African Americans who have attained a bachelors degree or higher."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 10¶\n",
    "\n",
    "**What are the implications of your answers to Exercise 7 and to Exercise 9 to how you interpret the Average Treatment Effect you estimated in Exercise 6?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above considerations in questions 7 and 9 change a few things about how we perceive our results from a regression on the likelihood of getting an interview call. It enhances the idea that it really is the race that is causing the treatment effect rather than college_education because the intercept for the interaction between higher education and race is *not* significant. However, we notice that the percentage of applicants in our dataset with college degrees is much higher than the actual percentage of black adults in the US who have completed college. This means that our study may be externally invalid since the percentages seem to be very different."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "551c62dc04900b7c9656b03a0ed1114515bcd045db0a145f14557b857526032b"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
